import logging
from typing import Dict, Any, List, Optional
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from django.conf import settings
import json
import os

logger = logging.getLogger(__name__)

class LangChainRAGService:
    def __init__(self):
        # OpenAI API ì„¤ì •
        self.api_key = settings.OPENAI_API_KEY
        if not self.api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # LangChain ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.7,
            api_key=self.api_key
        )
        
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            api_key=self.api_key
        )
        
        # ë²¡í„° ìŠ¤í† ì–´ ì„¤ì •
        self.persist_directory = "./chroma_db"
        self.vectorstore = None
        self.retriever = None
        self.rag_chain = None
        
        # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
        self._setup_prompt_template()
        
        # ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        self._initialize_vectorstore()
    
    def _setup_prompt_template(self):
        """
        ì¼ì¼ í€´ì¦ˆìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì • (ì‰¬ì›€-ë³´í†µ ë‚œì´ë„)
        """
        self.prompt_template = """
ë‹¹ì‹ ì€ ì¹œí™˜ê²½ í™œë™ê³¼ ë…¹ìƒ‰ê¸ˆìœµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìê°€ ì œê³µí•œ ìµœì‹  ë‰´ìŠ¤ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì¼ì¼ í€´ì¦ˆ**ìš© ê°ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì¤‘ìš”**: ì¼ì¼ í€´ì¦ˆëŠ” ì¼ë°˜ ì‚¬ìš©ìë“¤ì´ ì‰½ê²Œ ì°¸ì—¬í•  ìˆ˜ ìˆì–´ì•¼ í•˜ë¯€ë¡œ **ì‰¬ì›€-ë³´í†µ ë‚œì´ë„**ë¡œë§Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

--- ìµœì‹  ë‰´ìŠ¤ ì •ë³´ ---
{context}
---

ìš”ì²­ ì£¼ì œ: {input}

**ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”**:
{{
    "quiz": [
        {{
            "question": "ë¬¸ì œ ë‚´ìš© (ì‰¬ì›€-ë³´í†µ ë‚œì´ë„)",
            "options": ["ì„ íƒì§€1", "ì„ íƒì§€2", "ì„ íƒì§€3", "ì„ íƒì§€4"],
            "correct_answer": 0,
            "explanation": "ì •ë‹µì— ëŒ€í•œ ê°„ë‹¨í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…"
        }}
    ],
    "topic": "ìš”ì²­ ì£¼ì œ",
    "difficulty": "ì‰¬ì›€-ë³´í†µ",
    "source_info": "ìµœì‹  ë‰´ìŠ¤ ê¸°ë°˜"
}}

**í€´ì¦ˆ ìƒì„± ì›ì¹™ (ì¼ì¼ í€´ì¦ˆìš©)**:
1. **ì‰¬ì›€-ë³´í†µ ë‚œì´ë„**: ì¼ë°˜ì¸ì´ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆì§€ë§Œ ì•½ê°„ì˜ ì‚¬ê³ ê°€ í•„ìš”í•œ ìˆ˜ì¤€
2. **êµ¬ì²´ì  ìˆ«ì ê¸ˆì§€**: ì •í™•í•œ ê¸ˆì•¡, ë‚ ì§œ, ìˆ˜ì¹˜ ë“±ì€ í”¼í•˜ê³  ê°œë…ì  ì´í•´ ì¤‘ì‹¬
3. **êµìœ¡ì  ê°€ì¹˜**: ë‹¨ìˆœ ì•”ê¸°ê°€ ì•„ë‹Œ ì´í•´ë¥¼ ë•ëŠ” ë¬¸ì œ
4. **ì‹¤ìš©ì„±**: ì¼ìƒìƒí™œì—ì„œ í™œìš© ê°€ëŠ¥í•œ ì •ë³´
5. **ëª…í™•í•œ ì„ íƒì§€**: í—·ê°ˆë¦¬ì§€ ì•ŠëŠ” ëª…í™•í•œ ì„ íƒì§€ ì œê³µ
6. **ì‹œì  ëª…ì‹œ**: ì–¸ì œì˜ ì •ë³´ì¸ì§€ ë°˜ë“œì‹œ í¬í•¨
7. **ì ì ˆí•œ ë‚œì´ë„**: ë„ˆë¬´ ì‰¬ìš´ ìƒì‹ ë¬¸ì œë³´ë‹¤ëŠ” ìµœì‹  íŠ¸ë Œë“œë‚˜ ì •ì±… ê´€ë ¨ ë¬¸ì œ

**ì£¼ì œë³„ ê°€ì´ë“œë¼ì¸**:
í™˜ê²½ ê´€ë ¨: ê¸°í›„ë³€í™”, ì¬í™œìš©, ì¹œí™˜ê²½ ìƒí™œìŠµê´€, íƒ„ì†Œì¤‘ë¦½, ì‹ ì¬ìƒì—ë„ˆì§€
ë…¹ìƒ‰ê¸ˆìœµ ê´€ë ¨: ESG íˆ¬ì, ê·¸ë¦°ë³¸ë“œ, ì¹œí™˜ê²½ ì¹´ë“œ, ê·¸ë¦°ë‰´ë”œ, íƒ„ì†Œë°°ì¶œê¶Œ

**ì˜ˆì‹œ (ì¼ì¼ í€´ì¦ˆ ìˆ˜ì¤€)**:
{{
    "question": "ë‹¤ìŒ ì¤‘ íƒ„ì†Œ ë°œìêµ­ì„ ì¤„ì´ëŠ” ê°€ì¥ íš¨ê³¼ì ì¸ ë°©ë²•ì€?",
    "options": ["ëŒ€ì¤‘êµí†µ ì´ìš©", "ì „ê¸°ì°¨ êµ¬ë§¤", "íƒœì–‘ê´‘ íŒ¨ë„ ì„¤ì¹˜", "ì¹œí™˜ê²½ ì œí’ˆ êµ¬ë§¤"],
    "correct_answer": 0,
    "explanation": "ëŒ€ì¤‘êµí†µ ì´ìš©ì€ ì¶”ê°€ ë¹„ìš© ì—†ì´ ë°”ë¡œ íƒ„ì†Œ ë°°ì¶œì„ ì¤„ì¼ ìˆ˜ ìˆëŠ” ê°€ì¥ íš¨ê³¼ì ì´ê³  ì ‘ê·¼í•˜ê¸° ì‰¬ìš´ ë°©ë²•ì…ë‹ˆë‹¤."
}}

**ì˜ëª»ëœ ì˜ˆì‹œ (í”¼í•´ì•¼ í•  ìœ í˜•)**:
{{
    "question": "ì¹œí™˜ê²½ì°¨ ë³´ê¸‰ì„ ëŠ˜ë¦¬ê¸° ìœ„í•œ ì •ë¶€ì˜ ì£¼ìš” ì •ì±…ì€?",
    "options": ["ë‚´ì—°ê¸°ê´€ì°¨ë¥¼ íì°¨í•˜ê±°ë‚˜ êµì²´í•˜ëŠ” ê²ƒ", "ì „ê¸°ì°¨ë¥¼ íŒë§¤í•˜ëŠ” ê²ƒ", "ì¹œí™˜ê²½ì°¨ ê°€ê²© ì¸ìƒ", "ìë™ì°¨ ë³´í—˜ë£Œ ì¸ìƒ"],
    "correct_answer": 0,
    "explanation": "ì´ëŸ° ë¬¸ì œëŠ” 0ë²ˆê³¼ 1ë²ˆì´ ëª¨ë‘ ë§ëŠ” ë‚´ìš©ì´ë¼ ì• ë§¤í•©ë‹ˆë‹¤."
}}

**ì˜¬ë°”ë¥¸ ì˜ˆì‹œ**:
{{
    "question": "ë‹¤ìŒ ì¤‘ íƒ„ì†Œ ë°°ì¶œì„ ê°€ì¥ ë§ì´ ì¤„ì¼ ìˆ˜ ìˆëŠ” êµí†µìˆ˜ë‹¨ì€?",
    "options": ["ëŒ€ì¤‘êµí†µ ì´ìš©", "ì „ê¸°ì°¨ ìš´ì „", "í•˜ì´ë¸Œë¦¬ë“œì°¨ ìš´ì „", "ë‚´ì—°ê¸°ê´€ì°¨ ìš´ì „"],
    "correct_answer": 0,
    "explanation": "ëŒ€ì¤‘êµí†µì€ ì—¬ëŸ¬ ì‚¬ëŒì´ í•¨ê»˜ ì´ìš©í•˜ë¯€ë¡œ ê°œì¸ë‹¹ íƒ„ì†Œ ë°°ì¶œëŸ‰ì´ ê°€ì¥ ì ìŠµë‹ˆë‹¤."
}}

**í”¼í•´ì•¼ í•  ë¬¸ì œ ìœ í˜•**:
- ì •í™•í•œ ê¸ˆì•¡ì´ë‚˜ ìˆ˜ì¹˜ë¥¼ ë¬»ëŠ” ë¬¸ì œ (ì˜ˆ: "15ì¡°9160ì–µ ì›")
- êµ¬ì²´ì ì¸ ë‚ ì§œë‚˜ ê¸°ê°„ì„ ë¬»ëŠ” ë¬¸ì œ
- ì „ë¬¸ì ì¸ ìš©ì–´ë‚˜ ë³µì¡í•œ ê°œë…
- ì•”ê¸° ìœ„ì£¼ì˜ ë¬¸ì œ
- ë„ˆë¬´ ì‰¬ìš´ ìƒì‹ ë¬¸ì œ (ì˜ˆ: "ì¹œí™˜ê²½ ê¸ˆìœµì˜ ëª©ì ì€?")

**ì¶”ì²œí•˜ëŠ” ë¬¸ì œ ìœ í˜•**:
- ìµœì‹  ì •ì±…ì´ë‚˜ íŠ¸ë Œë“œ ê´€ë ¨ ë¬¸ì œ
- ì‹¤ìƒí™œì—ì„œ ì ìš© ê°€ëŠ¥í•œ ì¹œí™˜ê²½ ë°©ë²•
- ESG íˆ¬ìë‚˜ ë…¹ìƒ‰ê¸ˆìœµì˜ êµ¬ì²´ì  ì‚¬ë¡€
- í™˜ê²½ ë³´í˜¸ì™€ ê²½ì œ ì„±ì¥ì˜ ì—°ê´€ì„±

**ì„ íƒì§€ ì‘ì„± ì›ì¹™ (ë§¤ìš° ì¤‘ìš”)**:
- ì •ë‹µì€ ëª…í™•í•˜ê³  ìœ ì¼í•´ì•¼ í•¨
- ì˜¤ë‹µì€ í™•ì‹¤íˆ í‹€ë¦° ë‚´ìš©ì´ì–´ì•¼ í•¨
- ì• ë§¤í•˜ê±°ë‚˜ ë¶€ë¶„ì ìœ¼ë¡œ ë§ëŠ” ì„ íƒì§€ ê¸ˆì§€
- í—·ê°ˆë¦´ ìˆ˜ ìˆëŠ” ìœ ì‚¬í•œ ì„ íƒì§€ í”¼í•˜ê¸°
- ì •ë‹µê³¼ ì˜¤ë‹µ ì‚¬ì´ì— ëª…í™•í•œ êµ¬ë¶„ì´ ìˆì–´ì•¼ í•¨
- ì˜¤ë‹µì€ ë…¼ë¦¬ì ìœ¼ë¡œ í‹€ë¦¬ê±°ë‚˜ ê´€ë ¨ ì—†ëŠ” ë‚´ìš©ì´ì–´ì•¼ í•¨

**ì„ íƒì§€ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
1. ì •ë‹µì´ ìœ ì¼í•œê°€?
2. ì˜¤ë‹µë“¤ì´ í™•ì‹¤íˆ í‹€ë¦°ê°€?
3. ì„ íƒì§€ë“¤ ì‚¬ì´ì— ì• ë§¤í•¨ì´ ì—†ëŠ”ê°€?
4. ì‚¬ìš©ìê°€ í—·ê°ˆë¦´ ìˆ˜ ìˆëŠ”ê°€?

ìœ„ ë‰´ìŠ¤ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì •í™•í•˜ê³  êµìœ¡ì ì¸ ì¼ì¼ í€´ì¦ˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
        
        self.quiz_prompt = ChatPromptTemplate.from_template(self.prompt_template)
    
    def _initialize_vectorstore(self):
        """
        ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        """
        try:
            # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹œë„
            if os.path.exists(self.persist_directory):
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embeddings
                )
                logger.info("ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ")
            else:
                # ë¹ˆ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embeddings
                )
                logger.info("ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")
            
            # ê²€ìƒ‰ê¸° ì„¤ì •
            self.retriever = self.vectorstore.as_retriever(
                search_kwargs={"k": 5}  # ìƒìœ„ 5ê°œ ë¬¸ì„œ ê²€ìƒ‰
            )
            
            # RAG ì²´ì¸ êµ¬ì„±
            document_chain = create_stuff_documents_chain(self.llm, self.quiz_prompt)
            self.rag_chain = create_retrieval_chain(self.retriever, document_chain)
            
            logger.info("LangChain RAG ì²´ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def add_news_to_vectorstore(self, articles: List[Dict[str, Any]]) -> bool:
        """
        ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
        """
        try:
            if not articles:
                logger.warning("ì¶”ê°€í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ë¬¸ì„œ ë³€í™˜
            documents = []
            for article in articles:
                # ì œëª© + ë‚´ìš©ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
                text = f"ì œëª©: {article['title']}\nì¶œì²˜: {article['source']}\në‚ ì§œ: {article['date']}\në‚´ìš©: {article['content']}"
                
                # LangChain Document ê°ì²´ ìƒì„±
                from langchain_core.documents import Document
                doc = Document(
                    page_content=text,
                    metadata={
                        'title': article['title'],
                        'source': article['source'],
                        'date': article['date'],
                        'url': article['url']
                    }
                )
                documents.append(doc)
            
            # í…ìŠ¤íŠ¸ ë¶„í• 
            chunks = self.text_splitter.split_documents(documents)
            
            # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
            self.vectorstore.add_documents(chunks)
            
            # ê²€ìƒ‰ê¸° ì—…ë°ì´íŠ¸
            self.retriever = self.vectorstore.as_retriever(
                search_kwargs={"k": 5}
            )
            
            # RAG ì²´ì¸ ì¬êµ¬ì„±
            document_chain = create_stuff_documents_chain(self.llm, self.quiz_prompt)
            self.rag_chain = create_retrieval_chain(self.retriever, document_chain)
            
            logger.info(f"ë‰´ìŠ¤ {len(articles)}ê°œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False
    
    def generate_daily_quiz(self, topic: str = "ì¹œí™˜ê²½ í™œë™") -> Dict[str, Any]:
        """
        ì¼ì¼ í€´ì¦ˆ ìƒì„± (ì‰¬ì›€-ë³´í†µ ë‚œì´ë„)
        """
        try:
            logger.info(f"ì¼ì¼ í€´ì¦ˆ ìƒì„± ì‹œì‘ - ì£¼ì œ: {topic}")
            
            # RAG ì²´ì¸ ì‹¤í–‰
            user_query = f"{topic}ì— ëŒ€í•œ ì¼ì¼ í€´ì¦ˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ì‰¬ì›€-ë³´í†µ ë‚œì´ë„ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”."
            
            response = self.rag_chain.invoke({"input": user_query})
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                quiz_data = json.loads(response["answer"])
                
                result = {
                    'success': True,
                    'quiz': quiz_data.get('quiz', []),
                    'topic': quiz_data.get('topic', topic),
                    'difficulty': 'ì‰¬ì›€-ë³´í†µ',
                    'source_info': quiz_data.get('source_info', 'ìµœì‹  ë‰´ìŠ¤ ê¸°ë°˜'),
                    'model': 'gpt-4o-mini',
                    'rag_info': {
                        'used_rag': True,
                        'generation_method': 'LangChain RAG',
                        'context_documents': len(response.get('context', []))
                    }
                }
                
                logger.info(f"ì¼ì¼ í€´ì¦ˆ ìƒì„± ì™„ë£Œ - {len(result['quiz'])}ê°œ ë¬¸ì œ")
                return result
                
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
                return {
                    'success': True,
                    'quiz': [{
                        'question': 'ì¼ì¼ í€´ì¦ˆ',
                        'options': ['ì„ íƒì§€1', 'ì„ íƒì§€2', 'ì„ íƒì§€3', 'ì„ íƒì§€4'],
                        'correct_answer': 0,
                        'explanation': response["answer"]
                    }],
                    'topic': topic,
                    'difficulty': 'ì‰¬ì›€-ë³´í†µ',
                    'source_info': 'LangChain RAG ìƒì„±',
                    'model': 'gpt-4o-mini',
                    'rag_info': {
                        'used_rag': True,
                        'generation_method': 'LangChain RAG',
                        'context_documents': len(response.get('context', []))
                    }
                }
                
        except Exception as e:
            logger.error(f"ì¼ì¼ í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'quiz': []
            }
    
    def get_vectorstore_stats(self) -> Dict[str, Any]:
        """
        ë²¡í„° ìŠ¤í† ì–´ í†µê³„ ì¡°íšŒ
        """
        try:
            # ë¬¸ì„œ ê°œìˆ˜ ì¡°íšŒ
            all_docs = self.vectorstore.get()
            total_docs = len(all_docs['ids']) if all_docs['ids'] else 0
            
            # ì†ŒìŠ¤ë³„ í†µê³„
            source_stats = {}
            if all_docs['metadatas']:
                for metadata in all_docs['metadatas']:
                    source = metadata.get('source', 'Unknown')
                    source_stats[source] = source_stats.get(source, 0) + 1
            
            return {
                'total_documents': total_docs,
                'source_distribution': source_stats,
                'persist_directory': self.persist_directory,
                'embedding_model': 'text-embedding-3-small',
                'llm_model': 'gpt-4o-mini'
            }
            
        except Exception as e:
            logger.error(f"ë²¡í„° ìŠ¤í† ì–´ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def search_similar_documents(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
        """
        try:
            docs = self.vectorstore.similarity_search(query, k=k)
            
            results = []
            for doc in docs:
                result = {
                    'content': doc.page_content[:200] + "...",
                    'metadata': doc.metadata,
                    'relevance_score': 1.0  # LangChainì€ ê¸°ë³¸ì ìœ¼ë¡œ ì ìˆ˜ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ
                }
                results.append(result)
            
            return results
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

# í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜
def test_langchain_rag():
    """
    LangChain RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
    """
    try:
        print("ğŸ§ª LangChain RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        rag_service = LangChainRAGService()
        
        # í†µê³„ í™•ì¸
        stats = rag_service.get_vectorstore_stats()
        print(f"ğŸ“Š ë²¡í„° ìŠ¤í† ì–´ í†µê³„:")
        print(f"- ì´ ë¬¸ì„œ ìˆ˜: {stats.get('total_documents', 0)}ê°œ")
        print(f"- ì†ŒìŠ¤ë³„ ë¶„í¬: {stats.get('source_distribution', {})}")
        
        # ì¼ì¼ í€´ì¦ˆ ìƒì„± í…ŒìŠ¤íŠ¸
        print("\nğŸ¯ ì¼ì¼ í€´ì¦ˆ ìƒì„± í…ŒìŠ¤íŠ¸...")
        quiz_result = rag_service.generate_daily_quiz("ì¹œí™˜ê²½ ì—ë„ˆì§€")
        
        if quiz_result['success'] and quiz_result['quiz']:
            print(f"ì¼ì¼ í€´ì¦ˆ ìƒì„± ì„±ê³µ!")
            print(f"- ë¬¸ì œ ìˆ˜: {len(quiz_result['quiz'])}ê°œ")
            print(f"- ë‚œì´ë„: {quiz_result['difficulty']}")
            print(f"- RAG ì‚¬ìš©: {quiz_result['rag_info']['used_rag']}")
            
            # ì²« ë²ˆì§¸ ë¬¸ì œ ì¶œë ¥
            first_question = quiz_result['quiz'][0]
            print(f"\nì²« ë²ˆì§¸ ë¬¸ì œ:")
            print(f"Q: {first_question['question']}")
            print(f"A: {first_question['correct_answer']}")
            print(f"ì„¤ëª…: {first_question['explanation']}")
        else:
            print("âŒ ì¼ì¼ í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨")
        
        return True
        
    except Exception as e:
        print(f"âŒ LangChain RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    test_langchain_rag()
